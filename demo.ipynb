{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izKXA4b6-oIv",
    "outputId": "1b436740-e1e0-4e01-e3f5-6325ce29907a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'Span-ASTE'...\n",
      "remote: Enumerating objects: 191, done.\u001B[K\n",
      "remote: Counting objects: 100% (97/97), done.\u001B[K\n",
      "remote: Compressing objects: 100% (59/59), done.\u001B[K\n",
      "remote: Total 191 (delta 58), reused 61 (delta 36), pack-reused 94\u001B[K\n",
      "Receiving objects: 100% (191/191), 626.87 KiB | 23.22 MiB/s, done.\n",
      "Resolving deltas: 100% (80/80), done.\n",
      "Note: checking out 'f53ec3c'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n",
      "HEAD is now at f53ec3c Add command-line scoring instructions in README.md\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting Cython==0.29.21\n",
      "  Downloading Cython-0.29.21-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.0 MB 18.3 MB/s \n",
      "\u001B[?25hCollecting PYEVALB==0.1.3\n",
      "  Downloading PYEVALB-0.1.3-py3-none-any.whl (13 kB)\n",
      "Collecting allennlp-models==1.2.2\n",
      "  Downloading allennlp_models-1.2.2-py3-none-any.whl (353 kB)\n",
      "\u001B[K     |████████████████████████████████| 353 kB 69.5 MB/s \n",
      "\u001B[?25hCollecting allennlp==1.2.2\n",
      "  Downloading allennlp-1.2.2-py3-none-any.whl (505 kB)\n",
      "\u001B[K     |████████████████████████████████| 505 kB 39.7 MB/s \n",
      "\u001B[?25hCollecting botocore==1.19.46\n",
      "  Downloading botocore-1.19.46-py2.py3-none-any.whl (7.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 7.2 MB 34.0 MB/s \n",
      "\u001B[?25hCollecting fire==0.3.1\n",
      "  Downloading fire-0.3.1.tar.gz (81 kB)\n",
      "\u001B[K     |████████████████████████████████| 81 kB 10.6 MB/s \n",
      "\u001B[?25hCollecting nltk==3.6.6\n",
      "  Downloading nltk-3.6.6-py3-none-any.whl (1.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.5 MB 57.0 MB/s \n",
      "\u001B[?25hCollecting numpy==1.21.5\n",
      "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001B[K     |████████████████████████████████| 15.7 MB 49.4 MB/s \n",
      "\u001B[?25hCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001B[K     |████████████████████████████████| 9.5 MB 53.1 MB/s \n",
      "\u001B[?25hCollecting pydantic==1.6.2\n",
      "  Downloading pydantic-1.6.2-cp37-cp37m-manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 8.6 MB 28.2 MB/s \n",
      "\u001B[?25hCollecting scikit-learn==0.22.2.post1\n",
      "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 7.1 MB 48.9 MB/s \n",
      "\u001B[?25hCollecting torch==1.7.0\n",
      "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
      "\u001B[K     |████████████████████████████████| 776.7 MB 4.4 kB/s \n",
      "\u001B[?25hCollecting torchvision==0.8.1\n",
      "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
      "\u001B[K     |████████████████████████████████| 12.7 MB 41.9 MB/s \n",
      "\u001B[?25hCollecting transformers==3.4.0\n",
      "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.3 MB 58.1 MB/s \n",
      "\u001B[?25hCollecting boto3==1.16.46\n",
      "  Downloading boto3-1.16.46-py2.py3-none-any.whl (130 kB)\n",
      "\u001B[K     |████████████████████████████████| 130 kB 75.8 MB/s \n",
      "\u001B[?25hCollecting pytablewriter>=0.10.2\n",
      "  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n",
      "\u001B[K     |████████████████████████████████| 106 kB 71.7 MB/s \n",
      "\u001B[?25hCollecting word2number>=1.1\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001B[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
      "\u001B[?25hCollecting conllu==4.2.1\n",
      "  Downloading conllu-4.2.1-py2.py3-none-any.whl (14 kB)\n",
      "Collecting py-rouge==1.1\n",
      "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
      "\u001B[K     |████████████████████████████████| 56 kB 3.5 MB/s \n",
      "\u001B[?25hCollecting overrides==3.1.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.1.0)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (3.6.4)\n",
      "Collecting spacy<2.4,>=2.1.0\n",
      "  Downloading spacy-2.3.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001B[K     |████████████████████████████████| 4.8 MB 50.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (4.64.1)\n",
      "Collecting filelock<3.1,>=3.0\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (2.23.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.2.2->-r requirements.txt (line 4)) (1.7.3)\n",
      "Collecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001B[K     |████████████████████████████████| 125 kB 58.4 MB/s \n",
      "\u001B[?25hCollecting jsonnet>=0.10.0\n",
      "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
      "\u001B[K     |████████████████████████████████| 593 kB 72.4 MB/s \n",
      "\u001B[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "\u001B[K     |████████████████████████████████| 140 kB 67.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.19.46->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (1.15.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire==0.3.1->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (2022.6.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6->-r requirements.txt (line 7)) (7.1.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 9)) (2022.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (4.1.1)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0->-r requirements.txt (line 12)) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1->-r requirements.txt (line 13)) (7.1.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (3.19.6)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001B[K     |████████████████████████████████| 880 kB 67.9 MB/s \n",
      "\u001B[?25hCollecting tokenizers==0.9.2\n",
      "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.9 MB 45.8 MB/s \n",
      "\u001B[?25hCollecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.3 MB 62.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 14)) (21.3)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
      "\u001B[K     |████████████████████████████████| 73 kB 2.4 MB/s \n",
      "\u001B[?25hCollecting typepy[datetime]<2,>=1.2.0\n",
      "  Downloading typepy-1.3.0-py3-none-any.whl (31 kB)\n",
      "Collecting pathvalidate<3,>=2.3.0\n",
      "  Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n",
      "Collecting tabledata<2,>=1.3.0\n",
      "  Downloading tabledata-1.3.0-py3-none-any.whl (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0\n",
      "  Downloading mbstrdecoder-1.1.1-py3-none-any.whl (7.7 kB)\n",
      "Collecting DataProperty<2,>=0.55.0\n",
      "  Downloading DataProperty-0.55.0-py3-none-any.whl (26 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5\n",
      "  Downloading tcolorpy-0.1.2-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.7/dist-packages (from pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (57.4.0)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter>=0.10.2->PYEVALB==0.1.3->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.2.2->-r requirements.txt (line 4)) (2022.9.24)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001B[K     |████████████████████████████████| 127 kB 73.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.10.1)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001B[K     |████████████████████████████████| 208 kB 71.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (2.0.7)\n",
      "Collecting thinc<7.5.0,>=7.4.1\n",
      "  Downloading thinc-7.4.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.0 MB 58.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.0.8)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4,>=2.1.0->allennlp==1.2.2->-r requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models==1.2.2->-r requirements.txt (line 3)) (0.2.5)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==1.2.2->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle->allennlp==1.2.2->-r requirements.txt (line 4)) (4.13.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 14)) (3.0.9)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (1.11.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (9.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.2.2->-r requirements.txt (line 4)) (22.1.0)\n",
      "Building wheels for collected packages: fire, overrides, jsonnet, word2number, sacremoses\n",
      "  Building wheel for fire (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111023 sha256=867877500d51fc1466978cad4ed0d27cb550966ead11c09f6ebb1c29d326c4d7\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/38/e1/8b62337a8ecf5728bdc1017e828f253f7a9cf25db999861bec\n",
      "  Building wheel for overrides (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=f29e5574b1a87b6159f1a10bd1d4884e547a8f0c981fdf36b32f876ba81e67fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
      "  Building wheel for jsonnet (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp37-cp37m-linux_x86_64.whl size=3997237 sha256=65b35b399530104bd0f8d4c9e9854bf5b1ea5fa5ef562a7a2991994f048d31c4\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/6b/48/a168ed5f8d01c50268605eff341c29126286763607bf707e3b\n",
      "  Building wheel for word2number (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=db776042f55344c643ceb582cc4583b9f7af2c165fd065777f58e72b1fbb68e4\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=bf922fe785a540d21b8a0d5061ff77f1b7f7bdf172b948ea4af6e6b3817594b8\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built fire overrides jsonnet word2number sacremoses\n",
      "Installing collected packages: mbstrdecoder, urllib3, typepy, numpy, jmespath, srsly, plac, catalogue, botocore, tokenizers, thinc, sentencepiece, sacremoses, s3transfer, filelock, DataProperty, dataclasses, transformers, torch, tensorboardX, tcolorpy, tabledata, spacy, scikit-learn, pathvalidate, overrides, nltk, jsonpickle, jsonnet, boto3, word2number, pytablewriter, py-rouge, ftfy, conllu, allennlp, torchvision, PYEVALB, pydantic, pandas, fire, Cython, allennlp-models\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.5\n",
      "    Uninstalling srsly-2.4.5:\n",
      "      Successfully uninstalled srsly-2.4.5\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 2.0.8\n",
      "    Uninstalling catalogue-2.0.8:\n",
      "      Successfully uninstalled catalogue-2.0.8\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.1.5\n",
      "    Uninstalling thinc-8.1.5:\n",
      "      Successfully uninstalled thinc-8.1.5\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.8.0\n",
      "    Uninstalling filelock-3.8.0:\n",
      "      Successfully uninstalled filelock-3.8.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu113\n",
      "    Uninstalling torch-1.12.1+cu113:\n",
      "      Successfully uninstalled torch-1.12.1+cu113\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.4.3\n",
      "    Uninstalling spacy-3.4.3:\n",
      "      Successfully uninstalled spacy-3.4.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.1+cu113\n",
      "    Uninstalling torchvision-0.13.1+cu113:\n",
      "      Successfully uninstalled torchvision-0.13.1+cu113\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.2\n",
      "    Uninstalling pydantic-1.10.2:\n",
      "      Successfully uninstalled pydantic-1.10.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.32\n",
      "    Uninstalling Cython-0.29.32:\n",
      "      Successfully uninstalled Cython-0.29.32\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
      "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n",
      "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.7.0 which is incompatible.\n",
      "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\n",
      "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.8.1 which is incompatible.\n",
      "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.8 which is incompatible.\n",
      "confection 0.0.3 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.6.2 which is incompatible.\n",
      "confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001B[0m\n",
      "Successfully installed Cython-0.29.21 DataProperty-0.55.0 PYEVALB-0.1.3 allennlp-1.2.2 allennlp-models-1.2.2 boto3-1.16.46 botocore-1.19.46 catalogue-1.0.2 conllu-4.2.1 dataclasses-0.6 filelock-3.0.12 fire-0.3.1 ftfy-6.1.1 jmespath-0.10.0 jsonnet-0.19.1 jsonpickle-2.2.0 mbstrdecoder-1.1.1 nltk-3.6.6 numpy-1.21.5 overrides-3.1.0 pandas-1.1.5 pathvalidate-2.5.2 plac-1.1.3 py-rouge-1.1 pydantic-1.6.2 pytablewriter-0.64.2 s3transfer-0.3.7 sacremoses-0.0.53 scikit-learn-0.22.2.post1 sentencepiece-0.1.97 spacy-2.3.8 srsly-1.0.6 tabledata-1.3.0 tcolorpy-0.1.2 tensorboardX-2.5.1 thinc-7.4.6 tokenizers-0.9.2 torch-1.7.0 torchvision-0.8.1 transformers-3.4.0 typepy-1.3.0 urllib3-1.25.11 word2number-1.1\n",
      "Found existing installation: dataclasses 0.6\n",
      "Uninstalling dataclasses-0.6:\n",
      "  Successfully uninstalled dataclasses-0.6\n",
      "Archive:  data.zip\n",
      "   creating: aste/data/\n",
      "   creating: aste/data/triplet_data/\n",
      "   creating: aste/data/triplet_data/14lap/\n",
      "  inflating: aste/data/triplet_data/14lap/dev.txt  \n",
      "  inflating: aste/data/triplet_data/14lap/test.txt  \n",
      "  inflating: aste/data/triplet_data/14lap/train.txt  \n",
      "   creating: aste/data/triplet_data/14res/\n",
      "  inflating: aste/data/triplet_data/14res/dev.txt  \n",
      "  inflating: aste/data/triplet_data/14res/test.txt  \n",
      "  inflating: aste/data/triplet_data/14res/train.txt  \n",
      "   creating: aste/data/triplet_data/15res/\n",
      "  inflating: aste/data/triplet_data/15res/dev.txt  \n",
      "  inflating: aste/data/triplet_data/15res/test.txt  \n",
      "  inflating: aste/data/triplet_data/15res/train.txt  \n",
      "   creating: aste/data/triplet_data/16res/\n",
      "  inflating: aste/data/triplet_data/16res/dev.txt  \n",
      "  inflating: aste/data/triplet_data/16res/test.txt  \n",
      "  inflating: aste/data/triplet_data/16res/train.txt  \n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/chiayewken/Span-ASTE.git\n",
    "!cd Span-ASTE && git checkout f53ec3c\n",
    "!cp -a Span-ASTE/* .\n",
    "!echo boto3==1.16.46 >> requirements.txt\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pTnCgDxcSQ5",
    "outputId": "a461cd5d-5ed6-4c38-9144-b4149ee62952"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokens: ['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the', 'good', 'battery', 'life', '.']\n",
      "target: (16, 17)\n",
      "opinion: (15, 15)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['it', 'is', 'of', 'high', 'quality', ',', 'has', 'a', 'killer', 'GUI', ',', 'is', 'extremely', 'stable', ',', 'is', 'highly', 'expandable', ',', 'is', 'bundled', 'with', 'lots', 'of', 'very', 'good', 'applications', ',', 'is', 'easy', 'to', 'use', ',', 'and', 'is', 'absolutely', 'gorgeous', '.']\n",
      "target: (4, 4)\n",
      "opinion: (3, 3)\n",
      "label: LabelEnum.positive\n",
      "target: (9, 9)\n",
      "opinion: (8, 8)\n",
      "label: LabelEnum.positive\n",
      "target: (26, 26)\n",
      "opinion: (25, 25)\n",
      "label: LabelEnum.positive\n",
      "target: (31, 31)\n",
      "opinion: (29, 29)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['Easy', 'to', 'start', 'up', 'and', 'does', 'not', 'overheat', 'as', 'much', 'as', 'other', 'laptops', '.']\n",
      "target: (2, 3)\n",
      "opinion: (0, 0)\n",
      "label: LabelEnum.positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Data Exploration\n",
    "data_name = \"14lap\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from data_utils import Data\n",
    "\n",
    "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "data = Data.load_from_full_path(path)\n",
    "\n",
    "for s in data.sentences[:3]:\n",
    "    print(\"tokens:\", s.tokens)\n",
    "    for t in s.triples:\n",
    "        print(\"target:\", (t.t_start, t.t_end))\n",
    "        print(\"opinion:\", (t.o_start, t.o_end))\n",
    "        print(\"label:\", t.label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Download pretrained SpanModel weights\n",
    "from pathlib import Path\n",
    "template = \"https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/{}.tar\"\n",
    "url = template.format(data_name)\n",
    "model_tar = Path(url).name\n",
    "model_dir = Path(url).stem\n",
    "\n",
    "!wget -nc $url\n",
    "!tar -xf $model_tar"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LmrJekiPHpQ",
    "outputId": "0f62b4a9-8dd1-4363-b66f-1ae1661e6cab"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-11-30 07:39:51--  https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/14lap.tar\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/70bb2013-2773-44c0-b0d9-8a2ec8e38515?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221130%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221130T073951Z&X-Amz-Expires=300&X-Amz-Signature=10727051f65ed91031b2e1e8b05cf44384aae0bdafd0171b1655ca6c72249494&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3D14lap.tar&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-11-30 07:39:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/371216048/70bb2013-2773-44c0-b0d9-8a2ec8e38515?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221130%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221130T073951Z&X-Amz-Expires=300&X-Amz-Signature=10727051f65ed91031b2e1e8b05cf44384aae0bdafd0171b1655ca6c72249494&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=371216048&response-content-disposition=attachment%3B%20filename%3D14lap.tar&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 409068544 (390M) [application/octet-stream]\n",
      "Saving to: ‘14lap.tar’\n",
      "\n",
      "14lap.tar           100%[===================>] 390.12M  2.13MB/s    in 2m 21s  \n",
      "\n",
      "2022-11-30 07:42:13 (2.76 MB/s) - ‘14lap.tar’ saved [409068544/409068544]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488,
     "referenced_widgets": [
      "f61ea767ae064779b77f7d206a90b765",
      "382e7815e6314a798943a7f71eab1dbd",
      "b3f970d5f20748d091d13d1d37e712e4",
      "3c925c25029e4e5a9515b525a819cb31",
      "17148c3a40ae4572923f16f249179b9b",
      "9cc1d9231ee34d33b65a88c4de3b213f",
      "9afa9b48d00748739422b2e32763e57d",
      "f6d16c6d56974ec88f55333b65e0f16a",
      "e776ac7bd605497395d6cf45648c46e0",
      "87d171d5ff4d48bea3781c4185c53cd3",
      "ac44150d1166470f944a1d0effeae80b",
      "916c3c664f2348b5b608c368090945ac",
      "f00d08843e1a4e9e911a8d9fd11f04d1",
      "de26b5b4f1be42cba2951f528f7715ba",
      "d5d290cde75d463ba7b9b220eed79ca7",
      "e30953017bae40849979501dbb4647bc",
      "08b2e55d6325474da282c48e0f959a56",
      "542e865145b547ffbe61dec7fb94bab7",
      "1ac6bf7c4d7d4fbd8d1c85ec426854db",
      "808d2ba240c241e9a6989a03c4134a33",
      "886551311e7d4ee9823ecd34dfc82811",
      "988ec5ae620d4d67b6749ee92a2cb560",
      "9463e5ed29e74f05869715f4669d1fa5",
      "5e57195d10d7414c9f418af4e7eca84a",
      "e4bb3941e21d45f2b2327690b4d589bf",
      "321f61ce086b4ace9260a2d55afbdefa",
      "94f8b1fb0c764cfa9af078bd238623d4",
      "621130d9d8cf468abe5709a85f07d106",
      "1453b743641b45758303e91bfedafe03",
      "a7aeaf582d15403dbe447d57789b691f",
      "d1d0b028b6c04d59ada3bdfb7efde504",
      "0a203635e4a54efd96b85633164a067d",
      "c55350fd925a454eae62f9da4ed21962",
      "21dd3d5e1468453ab2f81d5e184a990e",
      "a18149514fe94397abd4bcafd4df0807",
      "c73b50f20f5f4b6c8ccca8e1ec61e738",
      "fb17189f06074ca39d8251ea2ece15f3",
      "b379be7248c84e88b3a5bc8362e56e2f",
      "7e85b97fbf8642ecb7613a8b3646b6dc",
      "f13fd92805504c0dae5b22e404c256fa",
      "86c67fc1ac0d47bbace0fe3b6f24c7ce",
      "46568a6cac834c86854b6e41c7e7219a",
      "fd38ef9382a6488a8be23d5bdb1fb533",
      "e01ecdf66c3143809825cbbad4aaeebb"
     ]
    },
    "id": "r3i4rnIhapWe",
    "outputId": "804a7c34-2089-4dab-b736-e2f92ba30f94"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f61ea767ae064779b77f7d206a90b765"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "916c3c664f2348b5b608c368090945ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9463e5ed29e74f05869715f4669d1fa5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "################################################################################\n",
      "################################################################################\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21dd3d5e1468453ab2f81d5e184a990e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "{'unused_keys': dict_keys([])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f26debbe680>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__relation_labels, Size: 3 || None__ner_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "reading instances: 1it [00:00, 350.58it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "{'target': 'Windows 8', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
      "\n",
      "{'target': 'touchscreen functions', 'opinion': 'Did not enjoy', 'sentiment': <LabelEnum.negative: 'NEG'>}\n",
      "\n",
      "{'target': 'Windows 8', 'opinion': 'new', 'sentiment': <LabelEnum.neutral: 'NEU'>}\n"
     ]
    }
   ],
   "source": [
    "# Use pretrained SpanModel weights for prediction\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from pathlib import Path\n",
    "from data_utils import Data, Sentence, SplitEnum\n",
    "from wrapper import SpanModel\n",
    "\n",
    "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
    "    path_in = \"temp_in.txt\"\n",
    "    path_out = \"temp_out.txt\"\n",
    "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=False, weight=1, id=0)\n",
    "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
    "    data.save_to_path(path_in)\n",
    "    model.predict(path_in, path_out)\n",
    "    data = Data.load_from_full_path(path_out)\n",
    "    return data.sentences[0]\n",
    "\n",
    "text = \"Did not enjoy the new Windows 8 and touchscreen functions .\"\n",
    "model = SpanModel(save_dir=model_dir, random_seed=0)\n",
    "sent = predict_sentence(text, model)\n",
    "\n",
    "for t in sent.triples:\n",
    "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
    "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
    "    print()\n",
    "    print(dict(target=target, opinion=opinion, sentiment=t.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "srSNwqUz-39x",
    "outputId": "9a34cc00-477f-4002-c8ec-e357284c2bc5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'weights_dir': PosixPath('outputs/14lap/seed_4/weights')}\n",
      "2022-11-30 03:01:13,590 - INFO - allennlp.common.params - random_seed = 4\n",
      "2022-11-30 03:01:13,592 - INFO - allennlp.common.params - numpy_seed = 4\n",
      "2022-11-30 03:01:13,596 - INFO - allennlp.common.params - pytorch_seed = 4\n",
      "2022-11-30 03:01:13,599 - INFO - allennlp.common.checks - Pytorch version: 1.7.0\n",
      "2022-11-30 03:01:13,600 - INFO - allennlp.common.params - type = default\n",
      "2022-11-30 03:01:13,604 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2022-11-30 03:01:13,606 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2022-11-30 03:01:13,608 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2022-11-30 03:01:13,610 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-11-30 03:01:13,612 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-11-30 03:01:13,613 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2022-11-30 03:01:13,615 - INFO - allennlp.common.params - dataset_reader.max_span_width = 8\n",
      "2022-11-30 03:01:13,617 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2022-11-30 03:01:13,618 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2022-11-30 03:01:13,620 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2022-11-30 03:01:13,621 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2022-11-30 03:01:13,623 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2022-11-30 03:01:13,625 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "################################################################################\n",
      "2022-11-30 03:01:13,627 - INFO - allennlp.common.params - train_data_path = /content/outputs/14lap/seed_4/temp_data/train.json\n",
      "2022-11-30 03:01:13,630 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f9692de6c90>\n",
      "2022-11-30 03:01:13,631 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
      "2022-11-30 03:01:13,633 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
      "2022-11-30 03:01:13,634 - INFO - allennlp.common.params - validation_data_path = /content/outputs/14lap/seed_4/temp_data/dev.json\n",
      "2022-11-30 03:01:13,636 - INFO - allennlp.common.params - validation_data_loader = None\n",
      "2022-11-30 03:01:13,637 - INFO - allennlp.common.params - test_data_path = /content/outputs/14lap/seed_4/temp_data/dev.json\n",
      "2022-11-30 03:01:13,639 - INFO - allennlp.common.params - evaluate_on_test = False\n",
      "2022-11-30 03:01:13,640 - INFO - allennlp.common.params - batch_weight_key = \n",
      "2022-11-30 03:01:13,642 - INFO - allennlp.training.util - Reading training data from /content/outputs/14lap/seed_4/temp_data/train.json\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "reading instances: 906it [00:01, 803.93it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:01:14,774 - INFO - allennlp.training.util - Reading validation data from /content/outputs/14lap/seed_4/temp_data/dev.json\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "reading instances: 219it [00:00, 1307.35it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:01:14,953 - INFO - allennlp.training.util - Reading test data from /content/outputs/14lap/seed_4/temp_data/dev.json\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "reading instances: 219it [00:00, 520.69it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:01:15,382 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-11-30 03:01:15,386 - INFO - allennlp.common.params - min_count = None\n",
      "2022-11-30 03:01:15,389 - INFO - allennlp.common.params - max_vocab_size = None\n",
      "2022-11-30 03:01:15,391 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
      "2022-11-30 03:01:15,394 - INFO - allennlp.common.params - pretrained_files = None\n",
      "2022-11-30 03:01:15,397 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
      "2022-11-30 03:01:15,401 - INFO - allennlp.common.params - tokens_to_add = None\n",
      "2022-11-30 03:01:15,402 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
      "2022-11-30 03:01:15,403 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
      "2022-11-30 03:01:15,405 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
      "2022-11-30 03:01:15,406 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "building vocab: 1344it [00:00, 14370.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:01:15,504 - INFO - allennlp.common.params - model.type = span_model\n",
      "2022-11-30 03:01:15,507 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-11-30 03:01:15,513 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2022-11-30 03:01:15,515 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2022-11-30 03:01:15,517 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
      "2022-11-30 03:01:15,519 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2022-11-30 03:01:15,520 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2022-11-30 03:01:15,521 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2022-11-30 03:01:15,523 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:01:15,525 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2022-11-30 03:01:15,526 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "2022-11-30 03:01:15,653 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2022-11-30 03:01:15,654 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
      "2022-11-30 03:01:15,657 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
      "2022-11-30 03:01:15,658 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2022-11-30 03:01:15,659 - INFO - allennlp.common.params - model.max_span_width = 8\n",
      "2022-11-30 03:01:15,660 - INFO - allennlp.common.params - model.target_task = relation\n",
      "2022-11-30 03:01:15,663 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
      "2022-11-30 03:01:15,665 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
      "2022-11-30 03:01:15,667 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
      "2022-11-30 03:01:15,669 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2022-11-30 03:01:15,670 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2022-11-30 03:01:15,672 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2022-11-30 03:01:15,673 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2022-11-30 03:01:15,674 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2022-11-30 03:01:15,676 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2022-11-30 03:01:15,677 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
      "2022-11-30 03:01:15,678 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
      "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "2022-11-30 03:01:15,680 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2022-11-30 03:01:15,681 - INFO - allennlp.common.params - ner.name = ner_labels\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "2022-11-30 03:01:15,687 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2022-11-30 03:01:15,688 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
      "2022-11-30 03:01:15,689 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2022-11-30 03:01:15,690 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2022-11-30 03:01:15,692 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
      "2022-11-30 03:01:15,693 - INFO - allennlp.common.params - relation.use_pruning = True\n",
      "{'unused_keys': dict_keys([])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f95ec5935f0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n",
      "2022-11-30 03:01:15,722 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-11-30 03:01:15,727 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2022-11-30 03:01:15,733 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2022-11-30 03:01:15,743 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
      "2022-11-30 03:01:15,745 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2022-11-30 03:01:15,746 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-11-30 03:01:15,748 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2022-11-30 03:01:15,749 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2022-11-30 03:01:15,750 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
      "2022-11-30 03:01:15,752 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-11-30 03:01:15,753 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
      "2022-11-30 03:01:15,754 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
      "2022-11-30 03:01:15,781 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
      "2022-11-30 03:01:15,783 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
      "2022-11-30 03:01:15,787 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2022-11-30 03:01:15,789 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-11-30 03:01:15,791 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2022-11-30 03:01:15,794 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2022-11-30 03:01:15,797 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
      "2022-11-30 03:01:15,799 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-11-30 03:01:15,802 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
      "2022-11-30 03:01:15,806 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-11-30 03:01:15,809 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-11-30 03:01:15,811 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-11-30 03:01:15,813 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-11-30 03:01:15,815 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-11-30 03:01:15,818 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-11-30 03:01:15,820 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,822 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,823 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,824 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,829 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-11-30 03:01:15,831 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-11-30 03:01:15,832 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-11-30 03:01:15,833 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-11-30 03:01:15,834 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-11-30 03:01:15,837 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-11-30 03:01:15,838 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-11-30 03:01:15,839 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-11-30 03:01:15,841 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,844 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,845 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-11-30 03:01:15,847 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-11-30 03:01:15,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-11-30 03:01:15,857 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-11-30 03:01:15,859 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-11-30 03:01:15,862 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-11-30 03:01:15,864 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-11-30 03:01:15,868 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-11-30 03:01:15,871 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-11-30 03:01:15,873 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-11-30 03:01:15,875 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,877 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,880 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-11-30 03:01:15,882 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-11-30 03:01:15,884 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,886 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,888 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,889 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,891 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-11-30 03:01:15,893 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-11-30 03:01:15,894 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-11-30 03:01:15,896 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-11-30 03:01:15,897 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-11-30 03:01:15,899 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-11-30 03:01:15,900 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-11-30 03:01:15,901 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-11-30 03:01:15,903 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,904 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,905 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-11-30 03:01:15,906 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-11-30 03:01:15,908 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,909 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,910 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,912 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,913 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-11-30 03:01:15,915 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-11-30 03:01:15,916 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-11-30 03:01:15,917 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-11-30 03:01:15,919 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-11-30 03:01:15,920 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-11-30 03:01:15,922 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-11-30 03:01:15,923 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-11-30 03:01:15,924 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,926 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,928 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-11-30 03:01:15,929 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-11-30 03:01:15,930 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,931 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,933 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,934 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,935 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-11-30 03:01:15,936 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-11-30 03:01:15,937 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-11-30 03:01:15,938 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-11-30 03:01:15,940 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-11-30 03:01:15,941 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-11-30 03:01:15,942 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-11-30 03:01:15,943 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-11-30 03:01:15,945 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,946 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,947 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-11-30 03:01:15,948 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-11-30 03:01:15,950 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,951 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,952 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,954 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,955 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-11-30 03:01:15,956 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-11-30 03:01:15,958 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-11-30 03:01:15,959 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-11-30 03:01:15,960 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-11-30 03:01:15,961 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-11-30 03:01:15,963 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-11-30 03:01:15,964 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-11-30 03:01:15,965 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,967 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,968 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-11-30 03:01:15,969 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-11-30 03:01:15,970 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,972 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,973 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,974 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,976 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-11-30 03:01:15,977 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-11-30 03:01:15,978 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-11-30 03:01:15,980 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-11-30 03:01:15,981 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-11-30 03:01:15,982 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-11-30 03:01:15,983 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-11-30 03:01:15,985 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-11-30 03:01:15,986 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,987 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,989 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-11-30 03:01:15,990 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-11-30 03:01:15,991 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:15,993 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:15,994 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-11-30 03:01:15,995 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-11-30 03:01:15,996 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-11-30 03:01:15,998 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-11-30 03:01:15,999 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-11-30 03:01:16,000 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-11-30 03:01:16,002 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-11-30 03:01:16,003 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-11-30 03:01:16,004 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,006 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,007 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,008 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,010 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-11-30 03:01:16,011 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-11-30 03:01:16,012 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,014 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,015 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,016 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,018 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-11-30 03:01:16,019 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-11-30 03:01:16,020 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-11-30 03:01:16,021 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-11-30 03:01:16,022 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-11-30 03:01:16,023 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-11-30 03:01:16,024 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,025 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,026 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,028 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,029 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-11-30 03:01:16,030 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-11-30 03:01:16,031 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,033 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,034 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,035 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,037 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-11-30 03:01:16,038 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-11-30 03:01:16,039 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-11-30 03:01:16,041 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-11-30 03:01:16,042 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-11-30 03:01:16,043 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-11-30 03:01:16,045 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,046 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,047 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,049 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,050 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-11-30 03:01:16,051 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-11-30 03:01:16,052 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,054 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,055 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,056 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,058 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-11-30 03:01:16,059 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-11-30 03:01:16,060 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-11-30 03:01:16,061 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-11-30 03:01:16,063 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-11-30 03:01:16,064 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-11-30 03:01:16,065 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,067 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,068 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,069 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,070 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2022-11-30 03:01:16,072 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-11-30 03:01:16,073 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,074 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,076 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,077 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,078 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-11-30 03:01:16,080 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-11-30 03:01:16,081 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-11-30 03:01:16,082 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-11-30 03:01:16,083 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-11-30 03:01:16,085 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-11-30 03:01:16,086 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,087 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,089 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,090 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,091 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-11-30 03:01:16,093 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-11-30 03:01:16,094 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2022-11-30 03:01:16,095 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2022-11-30 03:01:16,097 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2022-11-30 03:01:16,098 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2022-11-30 03:01:16,099 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2022-11-30 03:01:16,100 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2022-11-30 03:01:16,102 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2022-11-30 03:01:16,103 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2022-11-30 03:01:16,104 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2022-11-30 03:01:16,105 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2022-11-30 03:01:16,107 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2022-11-30 03:01:16,108 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2022-11-30 03:01:16,109 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
      "2022-11-30 03:01:16,111 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
      "2022-11-30 03:01:16,112 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
      "2022-11-30 03:01:16,113 - INFO - filelock - Lock 140284684846864 acquired on outputs/14lap/seed_4/weights/vocabulary/.lock\n",
      "2022-11-30 03:01:16,115 - INFO - filelock - Lock 140284684846864 released on outputs/14lap/seed_4/weights/vocabulary/.lock\n",
      "2022-11-30 03:01:16,116 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2022-11-30 03:01:16,118 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2022-11-30 03:01:16,119 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2022-11-30 03:01:16,120 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2022-11-30 03:01:16,122 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2022-11-30 03:01:16,123 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2022-11-30 03:01:16,124 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2022-11-30 03:01:16,125 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2022-11-30 03:01:16,127 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2022-11-30 03:01:16,128 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2022-11-30 03:01:16,129 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2022-11-30 03:01:16,131 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2022-11-30 03:01:16,132 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2022-11-30 03:01:16,134 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2022-11-30 03:01:16,136 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2022-11-30 03:01:16,137 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2022-11-30 03:01:16,139 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2022-11-30 03:01:16,140 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2022-11-30 03:01:16,142 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2022-11-30 03:01:16,143 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2022-11-30 03:01:16,144 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2022-11-30 03:01:16,146 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2022-11-30 03:01:16,147 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2022-11-30 03:01:16,148 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2022-11-30 03:01:16,149 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2022-11-30 03:01:16,151 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2022-11-30 03:01:16,152 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2022-11-30 03:01:16,154 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2022-11-30 03:01:16,155 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2022-11-30 03:01:16,157 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2022-11-30 03:01:16,158 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2022-11-30 03:01:16,160 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2022-11-30 03:01:16,161 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2022-11-30 03:01:16,162 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2022-11-30 03:01:16,164 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2022-11-30 03:01:16,165 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2022-11-30 03:01:16,167 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2022-11-30 03:01:16,168 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2022-11-30 03:01:16,169 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2022-11-30 03:01:16,171 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2022-11-30 03:01:16,172 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2022-11-30 03:01:16,173 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2022-11-30 03:01:16,175 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
      "2022-11-30 03:01:16,177 - INFO - allennlp.common.params - trainer.patience = None\n",
      "2022-11-30 03:01:16,178 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1\n",
      "2022-11-30 03:01:16,179 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
      "2022-11-30 03:01:16,181 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
      "2022-11-30 03:01:16,182 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
      "2022-11-30 03:01:16,184 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
      "2022-11-30 03:01:16,185 - INFO - allennlp.common.params - trainer.distributed = False\n",
      "2022-11-30 03:01:16,186 - INFO - allennlp.common.params - trainer.world_size = 1\n",
      "2022-11-30 03:01:16,188 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
      "2022-11-30 03:01:16,189 - INFO - allennlp.common.params - trainer.use_amp = False\n",
      "2022-11-30 03:01:16,191 - INFO - allennlp.common.params - trainer.no_grad = None\n",
      "2022-11-30 03:01:16,192 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
      "2022-11-30 03:01:16,194 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f9692e41190>\n",
      "2022-11-30 03:01:16,195 - INFO - allennlp.common.params - trainer.moving_average = None\n",
      "2022-11-30 03:01:16,196 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
      "2022-11-30 03:01:16,198 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
      "2022-11-30 03:01:16,199 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
      "2022-11-30 03:01:16,200 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
      "2022-11-30 03:01:16,508 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
      "2022-11-30 03:01:16,518 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
      "2022-11-30 03:01:16,520 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
      "2022-11-30 03:01:16,521 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
      "2022-11-30 03:01:16,522 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
      "2022-11-30 03:01:16,523 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
      "2022-11-30 03:01:16,526 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
      "2022-11-30 03:01:16,527 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
      "2022-11-30 03:01:16,530 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}\n",
      "2022-11-30 03:01:16,531 - INFO - allennlp.training.optimizers - Group 2: ['_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_relation._relation_scorers.None__relation_labels.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_relation.d_embedder.embedder.weight', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.1._module.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_relation._relation_scorers.None__relation_labels.weight'], {}\n",
      "2022-11-30 03:01:16,532 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name\n",
      "2022-11-30 03:01:16,534 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110249737\n",
      "2022-11-30 03:01:16,538 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
      "2022-11-30 03:01:16,542 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
      "2022-11-30 03:01:16,544 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
      "2022-11-30 03:01:16,545 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-11-30 03:01:16,547 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-11-30 03:01:16,548 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-11-30 03:01:16,549 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-11-30 03:01:16,550 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-11-30 03:01:16,552 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-11-30 03:01:16,553 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-11-30 03:01:16,554 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-11-30 03:01:16,556 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-11-30 03:01:16,557 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-11-30 03:01:16,558 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-11-30 03:01:16,559 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,561 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,562 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,563 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,564 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,566 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,567 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-11-30 03:01:16,568 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-11-30 03:01:16,570 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,571 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,572 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-11-30 03:01:16,573 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-11-30 03:01:16,575 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-11-30 03:01:16,576 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-11-30 03:01:16,577 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-11-30 03:01:16,578 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-11-30 03:01:16,580 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,581 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,582 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,583 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,585 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,586 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,587 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-11-30 03:01:16,589 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-11-30 03:01:16,590 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,591 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,592 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-11-30 03:01:16,594 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-11-30 03:01:16,595 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-11-30 03:01:16,596 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-11-30 03:01:16,598 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-11-30 03:01:16,599 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-11-30 03:01:16,600 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,602 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,603 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,604 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,605 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,607 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,608 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-11-30 03:01:16,609 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-11-30 03:01:16,611 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,612 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,613 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-11-30 03:01:16,614 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-11-30 03:01:16,616 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-11-30 03:01:16,617 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-11-30 03:01:16,618 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-11-30 03:01:16,620 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-11-30 03:01:16,621 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,622 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,623 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,625 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,626 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,627 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,628 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-11-30 03:01:16,629 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-11-30 03:01:16,631 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,632 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,633 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-11-30 03:01:16,634 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-11-30 03:01:16,635 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-11-30 03:01:16,637 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-11-30 03:01:16,638 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-11-30 03:01:16,639 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-11-30 03:01:16,640 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,641 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,642 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,643 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,644 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,645 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,647 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-11-30 03:01:16,648 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-11-30 03:01:16,649 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,650 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,651 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-11-30 03:01:16,653 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-11-30 03:01:16,654 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-11-30 03:01:16,655 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-11-30 03:01:16,656 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-11-30 03:01:16,658 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-11-30 03:01:16,659 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,660 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,661 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,661 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,663 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,664 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,665 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-11-30 03:01:16,666 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-11-30 03:01:16,667 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,668 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,669 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-11-30 03:01:16,670 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-11-30 03:01:16,671 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-11-30 03:01:16,674 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-11-30 03:01:16,675 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-11-30 03:01:16,676 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-11-30 03:01:16,677 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,679 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,680 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,681 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,682 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,683 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,685 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-11-30 03:01:16,686 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-11-30 03:01:16,687 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,688 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,689 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-11-30 03:01:16,690 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-11-30 03:01:16,691 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-11-30 03:01:16,692 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-11-30 03:01:16,694 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-11-30 03:01:16,695 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-11-30 03:01:16,696 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,697 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,698 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,700 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,701 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,702 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,703 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-11-30 03:01:16,705 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-11-30 03:01:16,706 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,707 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,708 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-11-30 03:01:16,710 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-11-30 03:01:16,711 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-11-30 03:01:16,712 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-11-30 03:01:16,713 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-11-30 03:01:16,714 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-11-30 03:01:16,716 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,717 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,718 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,720 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,721 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,722 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,723 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-11-30 03:01:16,725 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2022-11-30 03:01:16,726 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,727 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,728 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-11-30 03:01:16,730 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-11-30 03:01:16,731 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-11-30 03:01:16,732 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-11-30 03:01:16,733 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-11-30 03:01:16,735 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-11-30 03:01:16,736 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,737 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,738 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,740 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,741 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,742 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,744 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-11-30 03:01:16,746 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-11-30 03:01:16,747 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,748 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,749 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-11-30 03:01:16,751 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-11-30 03:01:16,752 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-11-30 03:01:16,753 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-11-30 03:01:16,754 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-11-30 03:01:16,756 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-11-30 03:01:16,757 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,758 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,760 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,761 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,762 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,763 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,765 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-11-30 03:01:16,766 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-11-30 03:01:16,767 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,836 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,837 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-11-30 03:01:16,839 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-11-30 03:01:16,840 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-11-30 03:01:16,841 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-11-30 03:01:16,842 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-11-30 03:01:16,844 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-11-30 03:01:16,845 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-11-30 03:01:16,846 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-11-30 03:01:16,848 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,849 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,850 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-11-30 03:01:16,859 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-11-30 03:01:16,893 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-11-30 03:01:16,895 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-11-30 03:01:16,898 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-11-30 03:01:16,900 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-11-30 03:01:16,902 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2022-11-30 03:01:16,904 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2022-11-30 03:01:16,906 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2022-11-30 03:01:16,907 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2022-11-30 03:01:16,910 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2022-11-30 03:01:16,912 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2022-11-30 03:01:16,913 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2022-11-30 03:01:16,914 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2022-11-30 03:01:16,915 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight\n",
      "2022-11-30 03:01:16,917 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2022-11-30 03:01:16,919 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2022-11-30 03:01:16,920 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2022-11-30 03:01:16,922 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2022-11-30 03:01:16,926 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight\n",
      "2022-11-30 03:01:16,928 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias\n",
      "2022-11-30 03:01:16,929 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
      "2022-11-30 03:01:16,932 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
      "2022-11-30 03:01:16,933 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
      "2022-11-30 03:01:16,935 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
      "2022-11-30 03:01:16,936 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
      "2022-11-30 03:01:16,941 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
      "2022-11-30 03:01:16,942 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
      "2022-11-30 03:01:16,943 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
      "2022-11-30 03:01:16,945 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
      "2022-11-30 03:01:16,946 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1\n",
      "2022-11-30 03:01:16,948 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
      "2022-11-30 03:01:16,949 - INFO - allennlp.common.params - summary_interval = 100\n",
      "2022-11-30 03:01:16,950 - INFO - allennlp.common.params - histogram_interval = None\n",
      "2022-11-30 03:01:16,951 - INFO - allennlp.common.params - batch_size_interval = None\n",
      "2022-11-30 03:01:16,952 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
      "2022-11-30 03:01:16,954 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
      "2022-11-30 03:01:16,955 - INFO - allennlp.common.params - get_batch_num_total = None\n",
      "2022-11-30 03:01:16,967 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "2022-11-30 03:01:16,968 - INFO - allennlp.training.trainer - Beginning training.\n",
      "2022-11-30 03:01:16,969 - INFO - allennlp.training.trainer - Epoch 0/9\n",
      "2022-11-30 03:01:16,971 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.0G\n",
      "2022-11-30 03:01:16,972 - INFO - allennlp.training.trainer - GPU 0 memory usage: 844M\n",
      "2022-11-30 03:01:16,974 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/906 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:01:17,437 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "MEAN__relation_precision: 0.0735, MEAN__relation_recall: 0.0541, MEAN__relation_f1: 0.0623, batch_loss: 4.1855, loss: 19.9654 ||: 100%|##########| 906/906 [01:29<00:00, 10.17it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:02:47,332 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "MEAN__relation_precision: 0.8919, MEAN__relation_recall: 0.0957, MEAN__relation_f1: 0.1728, batch_loss: 3.4678, loss: 9.2253 ||: 100%|##########| 219/219 [00:05<00:00, 40.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:02:52,748 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2022-11-30 03:02:52,752 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.062  |     0.173\n",
      "2022-11-30 03:02:52,759 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.073  |     0.892\n",
      "2022-11-30 03:02:52,762 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.054  |     0.096\n",
      "2022-11-30 03:02:52,764 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.330  |     0.716\n",
      "2022-11-30 03:02:52,768 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.320  |     0.707\n",
      "2022-11-30 03:02:52,770 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.340  |     0.725\n",
      "2022-11-30 03:02:52,772 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.330  |     0.716\n",
      "2022-11-30 03:02:52,774 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.320  |     0.707\n",
      "2022-11-30 03:02:52,776 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.340  |     0.725\n",
      "2022-11-30 03:02:52,778 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.062  |     0.173\n",
      "2022-11-30 03:02:52,780 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.073  |     0.892\n",
      "2022-11-30 03:02:52,782 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.054  |     0.096\n",
      "2022-11-30 03:02:52,784 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |   843.606  |       N/A\n",
      "2022-11-30 03:02:52,785 - INFO - allennlp.training.tensorboard_writer - loss                      |    19.965  |     9.225\n",
      "2022-11-30 03:02:52,787 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4127.316  |       N/A\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:02:55,895 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
      "2022-11-30 03:02:57,626 - INFO - allennlp.training.trainer - Epoch duration: 0:01:40.656161\n",
      "2022-11-30 03:02:57,632 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:15:05\n",
      "2022-11-30 03:02:57,636 - INFO - allennlp.training.trainer - Epoch 1/9\n",
      "2022-11-30 03:02:57,639 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
      "2022-11-30 03:02:57,644 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
      "2022-11-30 03:02:57,649 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "MEAN__relation_precision: 0.4882, MEAN__relation_recall: 0.3404, MEAN__relation_f1: 0.4011, batch_loss: 10.0549, loss: 9.5514 ||: 100%|##########| 906/906 [01:28<00:00, 10.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:04:27,788 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "MEAN__relation_precision: 0.7639, MEAN__relation_recall: 0.1594, MEAN__relation_f1: 0.2638, batch_loss: 8.5782, loss: 8.9333 ||: 100%|##########| 219/219 [00:05<00:00, 43.13it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:04:32,879 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2022-11-30 03:04:32,881 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.401  |     0.264\n",
      "2022-11-30 03:04:32,884 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.488  |     0.764\n",
      "2022-11-30 03:04:32,889 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.340  |     0.159\n",
      "2022-11-30 03:04:32,895 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.754  |     0.784\n",
      "2022-11-30 03:04:32,897 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.777  |     0.775\n",
      "2022-11-30 03:04:32,900 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.732  |     0.793\n",
      "2022-11-30 03:04:32,905 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.754  |     0.784\n",
      "2022-11-30 03:04:32,907 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.777  |     0.775\n",
      "2022-11-30 03:04:32,910 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.732  |     0.793\n",
      "2022-11-30 03:04:32,913 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.401  |     0.264\n",
      "2022-11-30 03:04:32,918 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.488  |     0.764\n",
      "2022-11-30 03:04:32,923 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.340  |     0.159\n",
      "2022-11-30 03:04:32,950 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
      "2022-11-30 03:04:32,952 - INFO - allennlp.training.tensorboard_writer - loss                      |     9.551  |     8.933\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:04:32,962 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4215.652  |       N/A\n",
      "2022-11-30 03:04:36,059 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
      "2022-11-30 03:04:38,109 - INFO - allennlp.training.trainer - Epoch duration: 0:01:40.472822\n",
      "2022-11-30 03:04:38,110 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:24\n",
      "2022-11-30 03:04:38,116 - INFO - allennlp.training.trainer - Epoch 2/9\n",
      "2022-11-30 03:04:38,120 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
      "2022-11-30 03:04:38,123 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
      "2022-11-30 03:04:38,129 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "MEAN__relation_precision: 0.6161, MEAN__relation_recall: 0.5089, MEAN__relation_f1: 0.5574, batch_loss: 1.6394, loss: 7.2603 ||: 100%|##########| 906/906 [01:28<00:00, 10.23it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:06:07,972 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "MEAN__relation_precision: 0.6667, MEAN__relation_recall: 0.4058, MEAN__relation_f1: 0.5045, batch_loss: 5.9121, loss: 12.1476 ||: 100%|##########| 219/219 [00:05<00:00, 42.53it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:06:13,133 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2022-11-30 03:06:13,139 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.557  |     0.505\n",
      "2022-11-30 03:06:13,141 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.616  |     0.667\n",
      "2022-11-30 03:06:13,144 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.509  |     0.406\n",
      "2022-11-30 03:06:13,147 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.860  |     0.796\n",
      "2022-11-30 03:06:13,149 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.879  |     0.795\n",
      "2022-11-30 03:06:13,152 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.842  |     0.797\n",
      "2022-11-30 03:06:13,155 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.860  |     0.796\n",
      "2022-11-30 03:06:13,158 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.879  |     0.795\n",
      "2022-11-30 03:06:13,160 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.842  |     0.797\n",
      "2022-11-30 03:06:13,164 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.557  |     0.505\n",
      "2022-11-30 03:06:13,169 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.616  |     0.667\n",
      "2022-11-30 03:06:13,172 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.509  |     0.406\n",
      "2022-11-30 03:06:13,182 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |  1871.789  |       N/A\n",
      "2022-11-30 03:06:13,189 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.260  |    12.148\n",
      "2022-11-30 03:06:13,192 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4215.652  |       N/A\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2022-11-30 03:06:16,292 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/14lap/seed_4/weights/best.th'.\n",
      "2022-11-30 03:06:18,593 - INFO - allennlp.training.trainer - Epoch duration: 0:01:40.476870\n",
      "2022-11-30 03:06:18,596 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:43\n",
      "2022-11-30 03:06:18,599 - INFO - allennlp.training.trainer - Epoch 3/9\n",
      "2022-11-30 03:06:18,601 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G\n",
      "2022-11-30 03:06:18,604 - INFO - allennlp.training.trainer - GPU 0 memory usage: 1.8G\n",
      "2022-11-30 03:06:18,608 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "MEAN__relation_precision: 0.7126, MEAN__relation_recall: 0.6330, MEAN__relation_f1: 0.6704, batch_loss: 11.1852, loss: 4.8294 ||:  14%|#3        | 126/906 [00:11<01:12, 10.76it/s]"
     ]
    }
   ],
   "source": [
    "# Train SpanModel from scratch\n",
    "random_seed = 4\n",
    "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
    "save_dir = f\"outputs/{data_name}/seed_{random_seed}\"\n",
    "\n",
    "model = SpanModel(save_dir=save_dir, random_seed=random_seed)\n",
    "model.fit(path_train, path_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yjyiKWjSF7oZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d7475f09-d593-48a9-a708-da3186dd575a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n",
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*weight_matrix\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "################################################################################\n",
      "################################################################################\n",
      "{'span_model_unused_keys': dict_keys(['serialization_dir'])}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "{'unused_keys': dict_keys([])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7f26de145f80>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pruning': True, 'kwargs': {}, 'vocab': Vocabulary with namespaces:  None__relation_labels, Size: 3 || None__ner_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "reading instances: 328it [00:00, 802.08it/s] \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n",
      "  \"path_pred\": \"pred.txt\",\n",
      "  \"path_gold\": \"aste/data/triplet_data/14lap/test.txt\",\n",
      "  \"precision\": 0.658695652173913,\n",
      "  \"recall\": 0.5580110497237569,\n",
      "  \"score\": 0.6041874376869392\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SpanModel F1 Score\n",
    "import json\n",
    "\n",
    "path_pred = \"pred.txt\"\n",
    "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
    "model.predict(path_in=path_test, path_out=path_pred)\n",
    "results = model.score(path_pred, path_test)\n",
    "print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f61ea767ae064779b77f7d206a90b765": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_382e7815e6314a798943a7f71eab1dbd",
       "IPY_MODEL_b3f970d5f20748d091d13d1d37e712e4",
       "IPY_MODEL_3c925c25029e4e5a9515b525a819cb31"
      ],
      "layout": "IPY_MODEL_17148c3a40ae4572923f16f249179b9b"
     }
    },
    "382e7815e6314a798943a7f71eab1dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cc1d9231ee34d33b65a88c4de3b213f",
      "placeholder": "​",
      "style": "IPY_MODEL_9afa9b48d00748739422b2e32763e57d",
      "value": "Downloading: 100%"
     }
    },
    "b3f970d5f20748d091d13d1d37e712e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6d16c6d56974ec88f55333b65e0f16a",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e776ac7bd605497395d6cf45648c46e0",
      "value": 433
     }
    },
    "3c925c25029e4e5a9515b525a819cb31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87d171d5ff4d48bea3781c4185c53cd3",
      "placeholder": "​",
      "style": "IPY_MODEL_ac44150d1166470f944a1d0effeae80b",
      "value": " 433/433 [00:00&lt;00:00, 13.3kB/s]"
     }
    },
    "17148c3a40ae4572923f16f249179b9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cc1d9231ee34d33b65a88c4de3b213f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9afa9b48d00748739422b2e32763e57d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6d16c6d56974ec88f55333b65e0f16a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e776ac7bd605497395d6cf45648c46e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "87d171d5ff4d48bea3781c4185c53cd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac44150d1166470f944a1d0effeae80b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "916c3c664f2348b5b608c368090945ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f00d08843e1a4e9e911a8d9fd11f04d1",
       "IPY_MODEL_de26b5b4f1be42cba2951f528f7715ba",
       "IPY_MODEL_d5d290cde75d463ba7b9b220eed79ca7"
      ],
      "layout": "IPY_MODEL_e30953017bae40849979501dbb4647bc"
     }
    },
    "f00d08843e1a4e9e911a8d9fd11f04d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08b2e55d6325474da282c48e0f959a56",
      "placeholder": "​",
      "style": "IPY_MODEL_542e865145b547ffbe61dec7fb94bab7",
      "value": "Downloading: 100%"
     }
    },
    "de26b5b4f1be42cba2951f528f7715ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ac6bf7c4d7d4fbd8d1c85ec426854db",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_808d2ba240c241e9a6989a03c4134a33",
      "value": 231508
     }
    },
    "d5d290cde75d463ba7b9b220eed79ca7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_886551311e7d4ee9823ecd34dfc82811",
      "placeholder": "​",
      "style": "IPY_MODEL_988ec5ae620d4d67b6749ee92a2cb560",
      "value": " 232k/232k [00:00&lt;00:00, 209kB/s]"
     }
    },
    "e30953017bae40849979501dbb4647bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08b2e55d6325474da282c48e0f959a56": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "542e865145b547ffbe61dec7fb94bab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ac6bf7c4d7d4fbd8d1c85ec426854db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "808d2ba240c241e9a6989a03c4134a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "886551311e7d4ee9823ecd34dfc82811": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "988ec5ae620d4d67b6749ee92a2cb560": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9463e5ed29e74f05869715f4669d1fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e57195d10d7414c9f418af4e7eca84a",
       "IPY_MODEL_e4bb3941e21d45f2b2327690b4d589bf",
       "IPY_MODEL_321f61ce086b4ace9260a2d55afbdefa"
      ],
      "layout": "IPY_MODEL_94f8b1fb0c764cfa9af078bd238623d4"
     }
    },
    "5e57195d10d7414c9f418af4e7eca84a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_621130d9d8cf468abe5709a85f07d106",
      "placeholder": "​",
      "style": "IPY_MODEL_1453b743641b45758303e91bfedafe03",
      "value": "Downloading: 100%"
     }
    },
    "e4bb3941e21d45f2b2327690b4d589bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7aeaf582d15403dbe447d57789b691f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1d0b028b6c04d59ada3bdfb7efde504",
      "value": 466062
     }
    },
    "321f61ce086b4ace9260a2d55afbdefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a203635e4a54efd96b85633164a067d",
      "placeholder": "​",
      "style": "IPY_MODEL_c55350fd925a454eae62f9da4ed21962",
      "value": " 466k/466k [00:01&lt;00:00, 503kB/s]"
     }
    },
    "94f8b1fb0c764cfa9af078bd238623d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "621130d9d8cf468abe5709a85f07d106": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1453b743641b45758303e91bfedafe03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7aeaf582d15403dbe447d57789b691f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1d0b028b6c04d59ada3bdfb7efde504": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a203635e4a54efd96b85633164a067d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c55350fd925a454eae62f9da4ed21962": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21dd3d5e1468453ab2f81d5e184a990e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a18149514fe94397abd4bcafd4df0807",
       "IPY_MODEL_c73b50f20f5f4b6c8ccca8e1ec61e738",
       "IPY_MODEL_fb17189f06074ca39d8251ea2ece15f3"
      ],
      "layout": "IPY_MODEL_b379be7248c84e88b3a5bc8362e56e2f"
     }
    },
    "a18149514fe94397abd4bcafd4df0807": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e85b97fbf8642ecb7613a8b3646b6dc",
      "placeholder": "​",
      "style": "IPY_MODEL_f13fd92805504c0dae5b22e404c256fa",
      "value": "Downloading: 100%"
     }
    },
    "c73b50f20f5f4b6c8ccca8e1ec61e738": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86c67fc1ac0d47bbace0fe3b6f24c7ce",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46568a6cac834c86854b6e41c7e7219a",
      "value": 440473133
     }
    },
    "fb17189f06074ca39d8251ea2ece15f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd38ef9382a6488a8be23d5bdb1fb533",
      "placeholder": "​",
      "style": "IPY_MODEL_e01ecdf66c3143809825cbbad4aaeebb",
      "value": " 440M/440M [00:07&lt;00:00, 52.8MB/s]"
     }
    },
    "b379be7248c84e88b3a5bc8362e56e2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e85b97fbf8642ecb7613a8b3646b6dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f13fd92805504c0dae5b22e404c256fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86c67fc1ac0d47bbace0fe3b6f24c7ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46568a6cac834c86854b6e41c7e7219a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd38ef9382a6488a8be23d5bdb1fb533": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e01ecdf66c3143809825cbbad4aaeebb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
